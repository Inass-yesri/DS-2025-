# ðŸ“Š Rapport dâ€™Analyse â€” Wine Quality Dataset

## ðŸŸ¦ Introduction

Le dataset **Wine Quality** est lâ€™un des jeux de donnÃ©es les plus utilisÃ©s en data science pour Ã©tudier la prÃ©diction de la qualitÃ© du vin Ã  partir de ses caractÃ©ristiques physico-chimiques. Issu de recherches universitaires portugaises, il constitue un excellent support dâ€™analyse exploratoire, de modÃ©lisation statistique et dâ€™apprentissage automatique.

Ce compte rendu vise Ã  rÃ©pondre aux questions fondamentales **quoi, comment, quand, oÃ¹, qui**, tout en situant ce dataset dans un contexte scientifique plus large. Nous prÃ©senterons Ã©galement des Ã©tudes similaires menÃ©es dans la littÃ©rature, dÃ©montrant lâ€™importance croissante de la modÃ©lisation des prÃ©fÃ©rences gustatives et du contrÃ´le qualitÃ© basÃ© sur les donnÃ©es.

---

## ðŸ“Œ 1. Quoi ? (Objet de lâ€™Ã©tude)

Le fichier contient deux datasets :

- **winequality-red.csv** : 1 599 Ã©chantillons de vin rouge  
- **winequality-white.csv** : 4 898 Ã©chantillons de vin blanc  

Ces donnÃ©es permettent de modÃ©liser la qualitÃ© du vin notÃ©e par des experts, Ã  partir de **11 mesures chimiques** telles que lâ€™aciditÃ©, lâ€™alcool, le pH, la densitÃ©, etc.

---

## ðŸ”§ 2. Comment ? (MÃ©thodologie utilisÃ©e)

Les donnÃ©es reposent sur deux types de mesures :

### ðŸ”¬ 2.1 Mesures physico-chimiques  
Chaque vin est analysÃ© selon 11 variables standardisÃ©es :

- fixed acidity  
- volatile acidity  
- citric acid  
- residual sugar  
- chlorides  
- free sulfur dioxide  
- total sulfur dioxide  
- density  
- pH  
- sulphates  
- alcohol  

### ðŸ‘… 2.2 Mesures sensorielles  
Un panel dâ€™experts attribue une note de **0 Ã  10**, formant la variable cible : `quality`.

Ces donnÃ©es permettent :

- la **rÃ©gression**,  
- la **classification**,  
- les analyses statistiques (corrÃ©lations, distributions),  
- lâ€™entraÃ®nement de modÃ¨les prÃ©dictifs (**SVM, Random Forest, XGBoost**, etc.).

---

## ðŸ“… 3. Quand ? (PÃ©riode)

- DonnÃ©es publiÃ©es en **2009**
- CollectÃ©es entre **2004 et 2007**

---

## ðŸ“ 4. OÃ¹ ? (Lieu)

Les vins proviennent de la rÃ©gion de **Vinho Verde** (Nord du Portugal).  
Les analyses ont Ã©tÃ© rÃ©alisÃ©es :

- dans des laboratoires Å“nologiques portugais,  
- en collaboration avec lâ€™**UniversitÃ© de Minho**.

---

## ðŸ‘¥ 5. Qui ? (Auteurs)

Les recherches ont Ã©tÃ© menÃ©es par :

- Paulo Cortez  
- AntÃ³nio Cerdeira  
- Fernando Almeida  
- Telmo Matos  
- JosÃ© Reis  

Publication originale :  
**Cortez et al. (2009)** â€“ *Modeling wine preferences by data mining from physicochemical properties*, Decision Support Systems.

---

## ðŸ“‚ 6. Structure des donnÃ©es

| Variable | Description |
|---------|-------------|
| fixed acidity | Acides non volatils |
| volatile acidity | Acide acÃ©tique |
| citric acid | AciditÃ© citrique |
| residual sugar | Sucre rÃ©siduel |
| chlorides | SalinitÃ© |
| free sulfur dioxide | Conservateur libre |
| total sulfur dioxide | Conservateur total |
| density | DensitÃ© |
| pH | AciditÃ© |
| sulphates | Additif |
| alcohol | Taux dâ€™alcool |
| quality | Note sensorielle |

---

## ðŸ” 7. Questions explorables

- Quels paramÃ¨tres influencent le plus la qualitÃ© ?
- Y a-t-il une diffÃ©rence entre vins rouges et blancs ?
- Peut-on prÃ©dire la qualitÃ© avec un modÃ¨le ML ?
- Lâ€™alcool amÃ©liore-t-il rÃ©ellement la note ?
- Quel est lâ€™impact du sucre, du pH ou des sulfites ?

---

## ðŸ“š 8. Ã‰tudes similaires

### âœ” Fernandes et al. (2015)  
Random Forest + rÃ©seaux de neurones pour prÃ©dire la qualitÃ© du vin.

### âœ” Zhang & Ma (2019)  
Comparaison de **SVM, KNN, Boosting**.

### âœ” Wine Quality Prediction (2020â€“2023)  
Approches diverses : PCA, Gradient Boosting, Deep Learning, clustering.

### âœ” Rapports OIV  
Utilisation dâ€™analyses statistiques similaires pour le contrÃ´le qualitÃ©.

---
```
# ======================================================
#   ANALYSE STATISTIQUE + ACP + VISUALISATIONS COMPLETES
# ======================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy.stats import shapiro

# ------------------------------------------------------
# 1) Charger la BDD
# ------------------------------------------------------
df = pd.read_csv("winequality-white.csv", sep=';')
print("\nAperÃ§u des donnÃ©es :")
print(df.head())

# ------------------------------------------------------
# 2) ANALYSE STATISTIQUE
# ------------------------------------------------------

print("\n===== STATISTIQUES DESCRIPTIVES =====")
print(df.describe().T)

# Valeurs manquantes
print("\n===== VALEURS MANQUANTES =====")
print(df.isnull().sum())

# ------------------------------------------------------
# 3) MATRICE DE CORRÃ‰LATION (GRAPHE)
# ------------------------------------------------------
plt.figure(figsize=(10,7))
sns.heatmap(df.corr(), cmap="coolwarm", annot=False)
plt.title("Heatmap de la matrice de corrÃ©lation")
plt.show()

# ------------------------------------------------------
# 4) DISTRIBUTION DES VARIABLES (HISTOGRAMMES)
# ------------------------------------------------------
df.hist(figsize=(14,10), bins=30)
plt.suptitle("Distribution des variables", fontsize=15)
plt.show()

# ------------------------------------------------------
# 5) BOXPLOTS (OUTLIERS)
# ------------------------------------------------------
plt.figure(figsize=(14,10))
for i, col in enumerate(df.columns):
    plt.subplot(4, 3, i+1)
    sns.boxplot(x=df[col])
    plt.title(col)
plt.tight_layout()
plt.show()

# ------------------------------------------------------
# 6) TEST DE NORMALITÃ‰ SHAPIRO-WILK
# ------------------------------------------------------
print("\n===== TEST SHAPIRO (NormalitÃ©) =====")
for col in df.columns:
    sample = df[col].sample(500, random_state=0)  # max pour Shapiro
    stat, p = shapiro(sample)
    print(f"{col}: p-value={p:.4f} -> {'Non normal' if p < 0.05 else 'Normal'}")

# ------------------------------------------------------
# 7) PREPARATION DES DONNÃ‰ES POUR Lâ€™ACP
# ------------------------------------------------------
X = df.drop(columns=['quality'])
y = df['quality']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ------------------------------------------------------
# 8) ACP
# ------------------------------------------------------
pca = PCA(n_components=5)
X_pca = pca.fit_transform(X_scaled)

explained_var = pca.explained_variance_ratio_
cum_var = np.cumsum(explained_var)

print("\n===== VARIANCE EXPLIQUÃ‰E =====")
for i, v in enumerate(explained_var, start=1):
    print(f"PC{i} : {v*100:.2f}%")

# -------------------------
# SCREE PLOT
# -------------------------
plt.figure(figsize=(7,5))
plt.plot(range(1, len(explained_var)+1), explained_var, marker='o')
plt.title("Scree plot - Variance expliquÃ©e")
plt.xlabel("Composante principale")
plt.ylabel("Variance expliquÃ©e")
plt.grid(True)
plt.show()

# -------------------------
# VARIANCE CUMULÃ‰E
# -------------------------
plt.figure(figsize=(7,5))
plt.plot(range(1, len(cum_var)+1), cum_var, marker='o')
plt.title("Variance expliquÃ©e cumulÃ©e")
plt.xlabel("Composantes")
plt.ylabel("Variance cumulÃ©e")
plt.grid(True)
plt.show()

# -------------------------
# PROJECTION PC1 vs PC2
# -------------------------
plt.figure(figsize=(8,6))
plt.scatter(X_pca[:,0], X_pca[:,1], c=y, cmap='viridis', alpha=0.7)
plt.colorbar(label="quality")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Projection ACP : PC1 vs PC2")
plt.grid(True)
plt.show()

# -------------------------
# BIPLOT (loadings + individus)
# -------------------------
loadings = pca.components_.T
features = X.columns

plt.figure(figsize=(8,6))
plt.scatter(X_pca[:,0], X_pca[:,1], alpha=0.4)

for i, var in enumerate(features):
    plt.arrow(0, 0, loadings[i,0]*3, loadings[i,1]*3, 
              color='red', head_width=0.05)
    plt.text(loadings[i,0]*3.2, loadings[i,1]*3.2, var, color='red')

plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Biplot ACP")
plt.axhline(0); plt.axvline(0)
plt.grid(True)
plt.show()

# -------------------------
# HEATMAP DES LOADINGS
# -------------------------
load_df = pd.DataFrame(loadings, index=features,
                       columns=[f"PC{i}" for i in range(1,6)])

plt.figure(figsize=(10,6))
sns.heatmap(load_df, annot=True, cmap="viridis")
plt.title("Loadings des variables sur les composantes principales")
plt.show()
```
# ðŸ“ˆ 9. Description de la BDD, Code Python, Analyses Statistiques & InterprÃ©tations

Cette section prÃ©sente :

- âœ” une **description complÃ¨te de la base de donnÃ©es**,  
- âœ” le **code Python** utilisÃ© pour lâ€™analyse,  
- âœ” des **analyses statistiques dÃ©taillÃ©es**,  
- âœ” une **interprÃ©tation approfondie** de chaque graphique.

---

## ðŸ—„ï¸ 9.1 Description de la base de donnÃ©es (BDD)

La base de donnÃ©es **Wine Quality** contient deux fichiers :

- **winequality-red.csv** : 1 599 observations de vins rouges  
- **winequality-white.csv** : 4 898 observations de vins blancs  

Chaque observation correspond Ã  un vin mesurÃ© selon **11 caractÃ©ristiques physico-chimiques** :

- fixed acidity  
- volatile acidity  
- citric acid  
- residual sugar  
- chlorides  
- free sulfur dioxide  
- total sulfur dioxide  
- density  
- pH  
- sulphates  
- alcohol  

La variable cible est :

- **quality** : note sensorielle (0 Ã  10)

Les donnÃ©es sont numÃ©riques, homogÃ¨nes et adaptÃ©es aux analyses statistiques, ACP, rÃ©gression, classification et machine learning.

---

## ðŸ’» 9.2 Code Python utilisÃ©

Voici le code Python de base pour charger, fusionner et explorer les donnÃ©es :

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Chargement des deux datasets
red = pd.read_csv("winequality-red.csv", sep=";")
white = pd.read_csv("winequality-white.csv", sep=";")

# Ajout dâ€™une colonne 'type' pour distinguer les deux vins
red["type"] = "red"
white["type"] = "white"

# Fusion
df = pd.concat([red, white], ignore_index=True)

# Affichage des premiÃ¨res lignes
print(df.head())

# Statistiques descriptives
print(df.describe())

# Distribution de la qualitÃ©
print(df["quality"].value_counts().sort_index())

## ðŸ§  Conclusion

Le dataset **Wine Quality** constitue un excellent cas dâ€™Ã©tude pour explorer la relation entre donnÃ©es chimiques objectives et Ã©valuations sensorielles subjectives. GrÃ¢ce Ã  sa structure claire et Ã  son adoption massive, il est idÃ©al pour :

- lâ€™analyse exploratoire,  
- la modÃ©lisation prÃ©dictive,  
- lâ€™apprentissage supervisÃ©,  
- la comparaison de modÃ¨les.

Les relations entre composition chimique et qualitÃ© perÃ§ue sont complexes mais modÃ©lisables, faisant de ce dataset un **benchmark incontournable** en data science.

---

