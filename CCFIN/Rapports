

# Introduction générale

Le dataset **Heart Disease (Cleveland)** est l’un des jeux de données médicaux les plus utilisés pour l’étude de la maladie coronarienne à l’aide des méthodes statistiques et de l’apprentissage automatique. Collecté à la fin des années 1970 et au début des années 1980 dans le cadre du *Coronary Artery Disease Investigation*, ce dataset regroupe des données cliniques standardisées provenant d’examens cardiaques réalisés sur des patients adultes. Son objectif principal est d’identifier les facteurs cliniques et biologiques permettant de prédire la présence d’une maladie coronarienne significative.

Le jeu de données Cleveland est considéré comme la référence parmi les quatre bases disponibles (Cleveland, Hungarian, Switzerland, Long Beach VA), car il s’agit de la seule base possédant des données complètes et exploitées dans la littérature scientifique. Comprendre son origine, sa méthodologie de collecte, sa population et ses limites est essentiel pour situer ces données dans leur cadre hospitalier réel.

---

# Questions principales et réponses détaillées

## 1. Qui a réalisé cette étude ?

L’étude a été menée par :

- Le **Cleveland Clinic Foundation**, centre hospitalier spécialisé en cardiologie, basé à Cleveland, Ohio (USA).
- Les chercheurs principaux incluent :  
  - **Dr. Robert Detrano**, cardiologue spécialiste des méthodes quantitatives ;  
  - Le groupe *Multivariate Computerized Diagnosis of Coronary Artery Disease*, composé de cardiologues, statisticiens et experts en informatique médicale.

Les fichiers du dataset font explicitement référence à **“ask-detrano”**, identifiant associé au Dr Detrano.

---

## 2. Quand cette étude a-t-elle été menée ?

- Collecte initiale : **1978–1988**  
- Publication au UCI Machine Learning Repository : **1988**  
- Publications scientifiques associées : **1989–1990**

---

## 3. Comment les données ont-elles été recueillies ?

Les données proviennent :

1. **D’un examen clinique standardisé**  
   - âge  
   - sexe  
   - type de douleur thoracique  
   - tension artérielle  
   - cholestérol sanguin  
   - glycémie à jeun  

2. **D’examens cardiologiques**  
   - électrocardiogramme (ECG) au repos  
   - test d’effort  
   - dépression du segment ST  
   - pente du ST après effort  

3. **D’une angiographie coronaire** (gold standard) confirmant la présence ou l’absence d’une maladie coronarienne.

Le dataset final contient **14 variables cliniques, biologiques et électrocardiographiques**.

---

## 4. Où cette étude a-t-elle été menée ?

- **Pays :** États-Unis  
- **Ville :** Cleveland, Ohio  
- **Institution principale :** Cleveland Clinic Foundation  
- **Contexte :** étude multicentrique internationale incluant également des données de :
  - Hongrie  
  - Suisse  
  - Hôpital Long Beach VA (Californie)

---

## 5. Quelle population a été étudiée ?

La population inclut :

- **303 patients** dans la version Cleveland originale  
- Adultes, hommes et femmes  
- Suspects de maladie coronarienne  

Deux classes diagnostiques :

- **0** : absence de maladie coronarienne significative  
- **1** : présence d’une coronaropathie (≥ 50 % de sténose)

---

## 6. Quelles autres études ont obtenu des résultats similaires ?

- **Detrano et al. (1990)**  
  → Algorithme de probabilité diagnostique validé sur plusieurs pays.

- **Janosi et al. (1988)**  
  → Analyse multivariée pionnière.

- **Chaudhary (2016)**  
  → SVM et réseaux neuronaux (~85–90 % de précision).

- **Fahad (2020)**  
  → Random Forest & Gradient Boosting (>92 %).

- **Mohammed (2021)**  
  → XGBoost / CatBoost (~94–96 %).

Ces travaux confirment la robustesse clinique de ce dataset.

---

# Questions complémentaires pertinentes

## 7. Quelle est la nature des variables mesurées ?

Les variables incluent :

- Données démographiques  
- Facteurs de risque (pression artérielle, cholestérol)  
- Type d’angine  
- ECG au repos  
- Résultats du test d’effort  
- Anomalies du segment ST  
- Angine induite  
- Nombre de vaisseaux colorés (angiographie)

---

## 8. Pourquoi ces caractéristiques sont-elles pertinentes médicalement ?

La coronaropathie se manifeste par :

- ischémie d’effort → anomalies ECG du ST  
- facteurs de risque → cholestérol, hypertension, âge  
- symptômes → douleur thoracique typique ou atypique  

Les variables mesurent donc directement les **mécanismes physiopathologiques** sous-jacents.

---

## 9. Quel est le design méthodologique de l’étude ?

Il s’agit d’une étude :

- **Observationnelle**  
- **Multicentrique**  
- Basée sur des **données cliniques réelles**  
- Validée par angiographie

---

## 10. Quelles limites méthodologiques doivent être considérées ?

- Dataset ancien (années 1980)  
- Absence de biomarqueurs modernes (ex. troponines)  
- Données manquantes dans certaines entrées  
- Variabilité entre centres hospitaliers

---

## 11. Le dataset peut-il être généralisé ?

Avec prudence :

- Population spécifique : années 1980, patients hospitalisés  
- Surreprésentation masculine  
- Absence de données ethniques  

Une validation sur des données contemporaines serait souhaitable.

---

## 12. Quels biais potentiels affectent les résultats ?

- **Biais de sélection** (patients hospitalisés)  
- **Biais techniques** (mesure du ST, ECG)  
- **Biais de centre** (Cleveland = dataset le plus complet)

---

## 13. Quels modèles de machine learning sont adaptés ?

- Logistic Regression  
- SVM  
- Random Forest  
- Gradient Boosting  
- Neural Networks  
- XGBoost / CatBoost

---

## 14. Quelles métriques sont pertinentes pour ce type d’étude ?

- **Sensibilité**  
- **Spécificité**  
- **AUC-ROC**  
- **F1-score**  
- **Courbe Precision-Recall**

---

## 15. Quel est l’intérêt clinique de ce dataset ?

Il permet :

- Le développement d’outils d’aide au diagnostic  
- L’analyse des facteurs de risque  
- La comparaison de modèles prédictifs  
- L’amélioration de la détection précoce de la maladie coronarienne

---

# Conclusion générale

Le dataset **Heart Disease – Cleveland** constitue une référence essentielle pour l’étude du diagnostic de la maladie coronarienne. Basé sur des données cliniques réelles, validé par angiographie, et largement utilisé dans la littérature scientifique, il demeure un benchmark incontournable pour l’apprentissage automatique appliqué à la cardiologie moderne. Malgré son ancienneté et certaines limites méthodologiques, il offre une base solide pour l’analyse prédictive et l’exploration des facteurs cliniques associés à la coronaropathie.

---

# MODULE 2 : STATISTIQUES POUR LA SCIENCE DES DONNÉES

## 2.1 Statistiques Descriptives

Les statistiques descriptives résument et décrivent les principales caractéristiques d'un ensemble de données.

### Mesures de tendance centrale

- **Moyenne** :  
  \[
  \bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i
  \]

- **Médiane** :  
  Valeur centrale divisant l’échantillon en deux parties égales.

- **Mode** :  
  Valeur la plus fréquente.

---

### Mesures de dispersion

- **Variance** :  
  \[
  s^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2
  \]

- **Écart-type** :  
  \[
  s = \sqrt{s^2}
  \]

- **Étendue** :  
  \[
  \max(x) - \min(x)
  \]

- **IQR (Écart interquartile)** :  
  \[
  IQR = Q3 - Q1
  \]

**Code Python - Statistiques descriptives :**

```python  
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Charger un dataset en ligne (exemple : ventes d'une entreprise)
url = "https://raw.githubusercontent.com/datasets/gdp/master/data/gdp.csv"
df = pd.read_csv(url)

# Afficher les premières lignes
print(df.head())

# Informations sur le dataset
print(df.info())

# Statistiques descriptives
print(df.describe())

# Statistiques pour une colonne spécifique
colonne = df['Value']  # Adapter selon vos données

print(f"Moyenne: {colonne.mean():.2f}")
print(f"Médiane: {colonne.median():.2f}")
print(f"Mode: {colonne.mode()[0]:.2f}")
print(f"Écart-type: {colonne.std():.2f}")
print(f"Variance: {colonne.var():.2f}")
print(f"Min: {colonne.min():.2f}")
print(f"Max: {colonne.max():.2f}")

# Quartiles
print(f"Q1 (25%): {colonne.quantile(0.25):.2f}")
print(f"Q2 (50% - Médiane): {colonne.quantile(0.50):.2f}")
print(f"Q3 (75%): {colonne.quantile(0.75):.2f}")
print(f"IQR: {colonne.quantile(0.75) - colonne.quantile(0.25):.2f}")

```

### 2.2 Visualisation des Statistiques Descriptives
```python
# Configuration du style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)

# Créer une figure avec plusieurs sous-graphiques
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. Histogramme
axes[0, 0].hist(colonne, bins=30, edgecolor='black', alpha=0.7)
axes[0, 0].set_title('Distribution des valeurs', fontsize=14, fontweight='bold')
axes[0, 0].set_xlabel('Valeur')
axes[0, 0].set_ylabel('Fréquence')

# Ajouter la moyenne et la médiane
axes[0, 0].axvline(colonne.mean(), color='red', linestyle='--', 
                   label=f'Moyenne: {colonne.mean():.2f}')
axes[0, 0].axvline(colonne.median(), color='green', linestyle='--', 
                   label=f'Médiane: {colonne.median():.2f}')
axes[0, 0].legend()

# 2. Boxplot
axes[0, 1].boxplot(colonne.dropna(), vert=True)
axes[0, 1].set_title('Boxplot - Détection des outliers', fontsize=14, fontweight='bold')
axes[0, 1].set_ylabel('Valeur')

# 3. Densité
colonne.plot(kind='density', ax=axes[1, 0])
axes[1, 0].set_title('Courbe de densité', fontsize=14, fontweight='bold')
axes[1, 0].set_xlabel('Valeur')

# 4. QQ-plot (pour tester la normalité)
from scipy import stats
stats.probplot(colonne.dropna(), dist="norm", plot=axes[1, 1])
axes[1, 1].set_title('Q-Q Plot (Test de normalité)', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()
```


